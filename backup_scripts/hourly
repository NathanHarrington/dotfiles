#!/bin/bash
#
# Run rclone to synchronize to the various list of manually configured
# drives. This expects the following configuration:
#
# StorageService:/auto_backup/time_frame/
#
# Where StorageService is google drive, dropbox, back blaze b2, etc.
# auto_backup is a directory in the root folder, and hourly, daily,
# weekly are manually created folders.
#
# Create links to this script like:
# ln -s hourly weekly
# ln -s hourly daily
# ln -s hourly 
#
# Then in crontab, run the weekly script every week, where it is smart
# enough to create a folder with a timestamp, and put the "hourly"
# folder in that directory. This is so you don't have to rely on
# dropbox's 50 or so versions.
#
# Copy the gpg file about 30 minutes after it has had time to be created
# 10 * * * * $HOME/projects/dotfiles/backup_scripts/hourly
# 
# Make a daily copy every day at 02:20 am
# 20 2 * * * $HOME/projects/dotfiles/backup_scripts/daily
#
# Make a weekly copy on friday at 02:30 am
# 30 2 * * 5 $HOME/projects/dotfiles/backup_scripts/weekly
#

# rclone remote names
declare -a dest=("wpdropbox" "wpgdrive")

RCLONE=/usr/sbin/rclone

HOSTNAME=$(hostname)
TAR_GPG_FILENAME="${HOSTNAME}_encrypted.tar.gpg"

SRC_FILENAME="$HOME/Documents/working_encrypted/$TAR_GPG_FILENAME"

SCRIPT_NAME=`basename "$0"`
LOCATION="/auto_backup/${SCRIPT_NAME}/"

# Only change the location name to include the timestamp if it's daily
# or weekly.
if [ "$SCRIPT_NAME" != "hourly" ]; then
    TIMESTAMP=`date`
    LOCATION="/auto_backup/${SCRIPT_NAME}/${TIMESTAMP}/"
fi

for DST_TYPE in "${dest[@]}"
do
    echo "$RCLONE sync $SRC_FILENAME $DST_TYPE:$LOCATION"
    $RCLONE sync $SRC_FILENAME "$DST_TYPE:$LOCATION"
done

